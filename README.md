# Grid-Supply Forecast Optimizer (Day 1: Setup & EDA)

## Overview
This repository contains **Day 1** of the Grid-Supply Forecast Optimizer project, focusing on:

- **Environment setup**: Python virtual environments on Windows with PowerShell execution policies adjusted for venv activation.  
- **Python version management**: Installing and switching between Python 3.13 and Python 3.12 to ensure package compatibility (notably SHAP).  
- **Dependency installation**: PySpark, Prophet, SHAP, pandas, matplotlib.  
- **Data ingestion**: Downloading NGED Live GSP CSVs (multiple GSP zones) from the National Grid portal.  
- **Exploratory Data Analysis (EDA)**:  
  - **Pandas scripts** (`eda_pandas.py`, `eda_multiple_gsps.py`) to load, inspect, and plot the data.  
  - **PySpark script** (`eda_spark.py`) to validate Spark ingestion and reproduce the same plots via Spark → pandas.

---

## Project Structure
GridSupplyForecast/
├── artifacts/ # Future outputs, Dockerfiles, etc.
├── images/ # Plots generated by EDA scripts
│ ├── bishops-wood_eda_pandas.png
│ ├── bushbury_eda_pandas.png
│ ├── bustleholm_eda_pandas.png
│ ├── cellarhead_eda_pandas.png
│ ├── … # one file per GSP
│ └── day2_baseline_plot.png # placeholder for Day 2
├── data/ # Raw NGED GSP CSV files
├── eda_pandas.py # Single-GSP EDA using pandas
├── eda_multiple_gsps.py # Loop over all GSP CSVs & plot first week
├── eda_spark.py # PySpark EDA: schema + sample→pandas plot
├── requirements.txt # Locked Day 1 dependencies
├── README.md # This file
├── venv/ # Python 3.13 venv (initial)
└── venv312/ # Python 3.12 venv (active Day 1 env)

---
## Setup Instructions
1. **Clone or download** this repository.  
2. **Open in VS Code**:  
   `File → Open Folder… → GridSupplyForecast`  
3. **Adjust PowerShell policy** (one-time):  
   ```powershell
   Set-ExecutionPolicy -Scope CurrentUser RemoteSigned

Activate the Python 3.12 venv:
.\venv312\Scripts\activate

Install dependencies:
pip install -r requirements.txt

Verify VS Code’s interpreter is set to:
.\venv312\Scripts\python.exe
(Bottom-right corner of the window.)

How to Run EDA
1. Pandas EDA (Single GSP)
python eda_pandas.py

* Loads one CSV from data/.
* Prints DataFrame info, head, and missing-value counts.
* Displays a matplotlib plot of hourly-averaged values.

2. Pandas EDA (Multiple GSPs)
python eda_multiple_gsps.py

* Iterates over all *_wmids.csv in the root.
* Prints info & head for each GSP.
* Plots the first 7 days’ hourly average for each GSP.

<details> <summary><strong>Day 1 Pandas EDA Plots</strong></summary>




…

</details>
3. Spark-Based EDA
python eda_spark.py

* Creates a local SparkSession (master="local[*]").
* Reads the same CSV with spark.read.csv(...).
* Prints Spark schema & first 5 rows.
* Converts a sample to pandas and displays the same hourly-average plot.

Note: Warnings about winutils.exe and HADOOP_HOME are harmless for local batch reads.

<details> <summary><strong>Example Spark EDA Plot</strong></summary>


</details>
Day 1 Observations
* Virtual env setup: Relaxed PowerShell policy; successfully activated Python 3.12 venv.
* SHAP wheel: Python 3.12 venv allowed pip install shap without C++ compilation errors.
* Data ingestion: All GSP CSVs loaded correctly; no missing timestamps.
* EDA insights: Clear daily and weekly demand/import patterns visible across GSPs.